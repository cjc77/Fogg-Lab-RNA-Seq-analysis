{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import utils.dev_config as dev_conf\n",
    "import utils.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_conf.get_dev_directories(\"../dev_paths.txt\")\n",
    "unified_dsets = [\"unified_cervical_data\", \"unified_uterine_data\", \"unified_uterine_endometrial_data\"]\n",
    "matrisome_list = f\"{dirs.data_dir}/matrisome/matrisome_hs_masterlist.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrisome_df = prep.load_matrisome_df(matrisome_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and filter survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_code = {\"Alive\": 0, \"Dead\": 1}\n",
    "covariate_cols = [\"age_at_diagnosis\", \"bmi\", \"race\", \"ethnicity\"]\n",
    "dep_cols = [\"vital_status\", \"survival_time\"]\n",
    "cat_cols = [\"race\", \"ethnicity\"]\n",
    "survival_df = prep.load_survival_df(f\"{dirs.data_dir}/{unified_dsets[i]}/survival_data.tsv\", event_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216, 13)\n",
      "0.833976833976834\n"
     ]
    }
   ],
   "source": [
    "figo_df = (\n",
    "    survival_df[[\"sample_name\", \"figo_stage\"] + covariate_cols]\n",
    "        .dropna()\n",
    "        .pipe(pd.get_dummies, columns=cat_cols)\n",
    "        .sort_values(\"figo_stage\")\n",
    "        .reset_index(drop=True)\n",
    "        .assign(figo_stage_major = lambda x: x[\"figo_stage\"].apply(lambda s: re.findall(r\"IV|III|II|I\", s)[0]))\n",
    "        .assign(figo_stage_major_fact = lambda x: pd.factorize(x[\"figo_stage_major\"])[0] + 1)\n",
    "        .pipe(prep.cols_to_front, [\"sample_name\", \"figo_stage_major\", \"figo_stage_major_fact\"])\n",
    "        .drop([\"figo_stage_major\", \"figo_stage\"], axis=1)\n",
    "        .rename(columns={\"figo_stage_major_fact\": \"figo_stage\"})\n",
    ")\n",
    "\n",
    "print(figo_df.shape)\n",
    "print(figo_df.shape[0] / survival_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normalized matrisome count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_matrisome_counts_df = pd.read_csv(f\"{dirs.data_dir}/{unified_dsets[i]}/norm_matrisome_counts.tsv\", sep='\\t')\n",
    "norm_filtered_matrisome_counts_t_df = (\n",
    "    norm_matrisome_counts_df[[\"geneID\"] + list(figo_df.sample_name)]\n",
    "        .set_index(\"geneID\")                        # set as index so will be column names\n",
    "        .transpose()\n",
    "        .rename_axis(None, axis=1)                  # column.name will be set to \"geneID\", we don't want this\n",
    "        .reset_index()                              # \"sample_name\" should now be its own column\n",
    "        .rename({\"index\": \"sample_name\"}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = (\n",
    "    pd.merge(figo_df, norm_filtered_matrisome_counts_t_df, on=\"sample_name\")\n",
    "        .set_index(\"sample_name\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = joined_df.iloc[:, 1:].values\n",
    "y = joined_df.iloc[:, 0].values\n",
    "# Use y.max() instead of y.max() + 1, and subscript with\n",
    "# y - 1 because y falls in [1, 4] rather than [0, 3]\n",
    "y_one_hot = np.eye(y.max())[y - 1]\n",
    "\n",
    "# Shuffle data\n",
    "n = y.shape[0]\n",
    "perm = np.random.choice(n, size=n, replace=False)\n",
    "X = X[perm, :]\n",
    "y = y[perm]\n",
    "y_one_hot = y_one_hot[perm, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validated feature permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_permutation_importance(pipeline, X, y ,k):\n",
    "    kf = KFold(n_splits=k)\n",
    "    results = []\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # Train/retrain from scratch\n",
    "        pipeline.fit(X[train_idx], y[train_idx])\n",
    "        result = permutation_importance(pipeline, X[test_idx], y[test_idx], scoring=\"f1_weighted\", n_jobs=-1, n_repeats=5)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_df = (\n",
    "    pd.read_csv(\"svc_opt_res.csv\")\n",
    "        .rename(columns={\"min\": \"min_loss\"})\n",
    ")\n",
    "\n",
    "opt_params = svc_df.loc[svc_df.min_loss == svc_df.min_loss.min()].to_dict(\"records\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(\n",
    "    kernel=opt_params[\"kernel\"],\n",
    "    C=opt_params[\"C\"],\n",
    "    gamma=opt_params[\"gamma\"],\n",
    "    degree=opt_params[\"degree\"],\n",
    "    coef0=opt_params[\"coef0\"]\n",
    ")\n",
    "svc_pipeline = make_pipeline(StandardScaler(), svc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38502674 0.50733647 0.39147287 0.28297011 0.31819115]\n",
      "0.376999467369998\n"
     ]
    }
   ],
   "source": [
    "kv_score = cross_val_score(\n",
    "    svc_pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    cv=KFold(n_splits=5, shuffle=False),\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\"\n",
    ")\n",
    "print(kv_score)\n",
    "print(kv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_results = cv_permutation_importance(svc_pipeline, X, y, 5)\n",
    "svc_kv_importance_means = np.concatenate([r.importances for r in svc_results], axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(svc_kv_importance_means > 0))\n",
    "# print(np.sum(svc_kv_importance_means < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_model = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "#     penalty=\"l1\",\n",
    "    class_weight=\"balanced\",\n",
    "    multi_class=\"multinomial\",\n",
    "    C=1,\n",
    "    solver=\"newton-cg\"\n",
    "#     solver=\"saga\"\n",
    ")\n",
    "lrg_pipeline = make_pipeline(StandardScaler(), lrg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50029709 0.55395757 0.45200915 0.37928924 0.46269616]\n",
      "0.469649841791854\n"
     ]
    }
   ],
   "source": [
    "kv_score = cross_val_score(\n",
    "    lrg_pipeline,\n",
    "    X,\n",
    "    y,\n",
    "    cv=KFold(n_splits=5, shuffle=False),\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1_weighted\"\n",
    ")\n",
    "print(kv_score)\n",
    "print(kv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_results = cv_permutation_importance(lrg_pipeline, X, y, 5)\n",
    "lrg_kv_importance_means = np.concatenate([r.importances for r in lrg_results], axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "418\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(lrg_kv_importance_means > 0))\n",
    "# print(np.sum(lrg_kv_importance_means < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0206125 , -0.02056103, -0.01932727, ...,  0.01651336,\n",
       "        0.01664334,  0.01709878])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(lrg_kv_importance_means) / kv_score.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the naive model (guess the label with highest prevalence) perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.figo_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y, np.ones(shape=(216,)), average=\"weighted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
