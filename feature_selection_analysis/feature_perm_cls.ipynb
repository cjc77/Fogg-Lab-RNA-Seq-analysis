{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import utils.dev_config as dev_conf\n",
    "import utils.preprocessing as prep\n",
    "import utils.optimization as opt\n",
    "import utils.feature_selection as feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_conf.get_dev_directories(\"../dev_paths.txt\")\n",
    "unified_dsets = [\"unified_cervical_data\", \"unified_uterine_data\", \"unified_uterine_endometrial_data\"]\n",
    "matrisome_list = f\"{dirs.data_dir}/matrisome/matrisome_hs_masterlist.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrisome_df = prep.load_matrisome_df(matrisome_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rand = np.random.RandomState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and filter survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_code = {\"Alive\": 0, \"Dead\": 1}\n",
    "covariate_cols = [\"age_at_diagnosis\", \"race\", \"ethnicity\"]\n",
    "dep_cols = [\"figo_stage\"]\n",
    "cat_cols = [\"race\", \"ethnicity\"]\n",
    "survival_df = prep.load_survival_df(f\"{dirs.data_dir}/{unified_dsets[dset_idx]}/survival_data.tsv\", event_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 12)\n"
     ]
    }
   ],
   "source": [
    "filtered_survival_df = (\n",
    "    prep.decode_figo_stage(survival_df[[\"sample_name\"] + dep_cols + covariate_cols].dropna(), to=\"n\")\n",
    "        .pipe(pd.get_dummies, columns=cat_cols)\n",
    "        .reset_index(drop = True)\n",
    "        .pipe(prep.cols_to_front, [\"sample_name\", \"figo_num\"])\n",
    ")\n",
    "filtered_survival_df.columns = filtered_survival_df.columns.str.replace(' ', '_')\n",
    "print(filtered_survival_df.shape)\n",
    "# filtered_survival_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normalized matrisome count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1009)\n"
     ]
    }
   ],
   "source": [
    "norm_matrisome_counts_df = pd.read_csv(f\"{dirs.data_dir}/{unified_dsets[dset_idx]}/norm_matrisome_counts.tsv\", sep='\\t')\n",
    "norm_filtered_matrisome_counts_t_df = prep.transpose_df(\n",
    "    norm_matrisome_counts_df[[\"geneID\"] + list(filtered_survival_df.sample_name)], \"geneID\", \"sample_name\"\n",
    ")\n",
    "print(norm_filtered_matrisome_counts_t_df.shape)\n",
    "# norm_filtered_matrisome_counts_t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join survival and count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1019)\n"
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    pd.merge(filtered_survival_df, norm_filtered_matrisome_counts_t_df, on=\"sample_name\")\n",
    "        .set_index(\"sample_name\")\n",
    ")\n",
    "print(joined_df.shape)\n",
    "# joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrisome_genes = norm_filtered_matrisome_counts_t_df.columns[1:]\n",
    "n_matrisome_genes = len(matrisome_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lr(h_params):\n",
    "    if pd.isna(h_params[\"class_weight\"]):\n",
    "        h_params[\"class_weight\"] = None\n",
    "    model = make_pipeline(\n",
    "        ColumnTransformer([\n",
    "            (\"standard\", StandardScaler(), [\"age_at_diagnosis\"] + list(matrisome_genes))\n",
    "        ], remainder=\"passthrough\"),\n",
    "        LogisticRegression(\n",
    "            C=h_params[\"C\"],\n",
    "            class_weight=h_params[\"class_weight\"],\n",
    "            solver=h_params[\"solver\"],\n",
    "            penalty=h_params[\"penalty\"],\n",
    "            random_state=h_params[\"random_state\"],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_lr_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_lr_h_params_l1_f1_weighted.tsv\", sep=\"\\t\")\n",
    "l1_lrs = []\n",
    "for i in range(l1_lr_h_param_df.shape[0]):\n",
    "    l1_lr_h_params = {\n",
    "        **dict(zip(l1_lr_h_param_df.columns[:-1], l1_lr_h_param_df.iloc[i, :-1])), \"penalty\": \"l1\", \"random_state\": rand\n",
    "    }\n",
    "    l1_lrs.append(make_lr(l1_lr_h_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_lr_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_lr_h_params_l2_f1_weighted.tsv\", sep=\"\\t\")\n",
    "l2_lrs = []\n",
    "for i in range(l2_lr_h_param_df.shape[0]):\n",
    "    l2_lr_h_params = {\n",
    "        **dict(zip(l2_lr_h_param_df.columns[:-1], l2_lr_h_param_df.iloc[i, :-1])), \"penalty\": \"l2\", \"random_state\": rand\n",
    "    }\n",
    "    l2_lrs.append(make_lr(l2_lr_h_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_gbc_h_params_f1_weighted.tsv\", sep=\"\\t\")\n",
    "gbcs = [\n",
    "    GradientBoostingClassifier(\n",
    "        **dict(zip(gbc_h_param_df.columns[:-1], gbc_h_param_df.iloc[i, :-1])), loss=\"deviance\", random_state=rand\n",
    "    ) for i in range(gbc_h_param_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_rfc_h_params_f1_weighted.tsv\", sep=\"\\t\")\n",
    "rfcs = [\n",
    "    RandomForestClassifier(\n",
    "        **dict(zip(rfc_h_param_df.columns[:-1], rfc_h_param_df.iloc[i, :-1])), random_state=rand, n_jobs=-1\n",
    "    ) for i in range(rfc_h_param_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_feature_perm_results(models, x_df, y_df, r, gene_cols, score, verbose=True, to_array=True):\n",
    "    all_mean_perm_results = []\n",
    "    all_ref_scores = []\n",
    "    all_perm_res_dfs = []\n",
    "    \n",
    "    for i, m in enumerate(models):\n",
    "        if verbose:\n",
    "            print(f\"Running feature perm for model {i}\")\n",
    "        perm_results, ref_scores = opt.cv_permutation_importance(m, x_df, y_df, score, k=5, random_state=r, to_array=to_array)\n",
    "        perm_importances = np.concatenate([r.importances for r in perm_results], axis=1)\n",
    "        perm_importance_means = np.mean(perm_importances, axis=1)\n",
    "        \n",
    "        all_mean_perm_results.append(perm_importance_means)\n",
    "        all_ref_scores.append(ref_scores)\n",
    "        \n",
    "        res_df = feat_sel.gather_perm_res(x_df, perm_importance_means, np.mean(ref_scores), gene_cols)\n",
    "        res_df = res_df.rename(columns={\"mean_imp\": f\"mean_imp_{i}\", \"score_pct_improvement\": f\"score_pct_improvement_{i}\"})\n",
    "        all_perm_res_dfs.append(res_df)\n",
    "    \n",
    "    return all_mean_perm_results, all_ref_scores, all_perm_res_dfs\n",
    "\n",
    "\n",
    "def merge_perm_results(perm_res_dfs, importance_thresh=0):\n",
    "    merge_df = perm_res_dfs[0]\n",
    "    for i in range(1, len(perm_res_dfs)):\n",
    "        merge_df = merge_df.merge(perm_res_dfs[i], on = \"geneID\", how = \"inner\")\n",
    "    merge_df = (\n",
    "        merge_df.assign(consensus_imp_mean = merge_df.filter(regex=\"mean_imp\").mean(axis=1))\n",
    "            .assign(consensus_imp_std = merge_df.filter(regex=\"mean_imp\").std(axis=1))\n",
    "    )\n",
    "    merge_df = merge_df.assign(consensus_imp_cv = merge_df.consensus_imp_std / merge_df.consensus_imp_mean)\n",
    "    merge_df[\"consensus_vote\"] = (merge_df.set_index(\"geneID\").filter(regex=\"mean_imp\", axis=1) > importance_thresh).all(axis=1).values\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(seed)\n",
    "x_df, y_df = prep.shuffle_data(joined_df, rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR (L1 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/home/carcook/anaconda3/envs/TCGA-round1/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "l1_lr_mean_perm_res, l1_lr_ref_scores, l1_lr_perm_res_dfs = collect_feature_perm_results(\n",
    "    l1_lrs, x_df, y_df, rand, matrisome_genes, \"f1_weighted\", to_array=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_lr_merge_df = merge_perm_results(l1_lr_perm_res_dfs)\n",
    "l1_lr_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50164974, 0.50897904, 0.49894685, 0.4960666 , 0.49307874])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l1_lr_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR (L2 penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 0\n",
      "Running feature perm for model 1\n",
      "Running feature perm for model 2\n",
      "Running feature perm for model 3\n",
      "Running feature perm for model 4\n"
     ]
    }
   ],
   "source": [
    "l2_lr_mean_perm_res, l2_lr_ref_scores, l2_lr_perm_res_dfs = collect_feature_perm_results(\n",
    "    l2_lrs, x_df, y_df, rand, matrisome_genes, \"f1_weighted\", to_array=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_lr_merge_df = merge_perm_results(l2_lr_perm_res_dfs)\n",
    "l2_lr_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50974458, 0.50974458, 0.50974458, 0.50974458, 0.50778366])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l2_lr_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 0\n",
      "Running feature perm for model 1\n",
      "Running feature perm for model 2\n",
      "Running feature perm for model 3\n",
      "Running feature perm for model 4\n"
     ]
    }
   ],
   "source": [
    "gbc_mean_perm_res, gbc_ref_scores, gbc_perm_res_dfs = collect_feature_perm_results(\n",
    "    gbcs, x_df, y_df, rand, matrisome_genes, \"f1_weighted\", to_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_merge_df = merge_perm_results(gbc_perm_res_dfs)\n",
    "gbc_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48539758, 0.47589069, 0.47466133, 0.48404418, 0.4743963 ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(gbc_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 0\n",
      "Running feature perm for model 1\n",
      "Running feature perm for model 2\n",
      "Running feature perm for model 3\n",
      "Running feature perm for model 4\n"
     ]
    }
   ],
   "source": [
    "rfc_mean_perm_res, rfc_ref_scores, rfc_perm_res_dfs = collect_feature_perm_results(\n",
    "    rfcs, x_df, y_df, rand, matrisome_genes, \"f1_weighted\", to_array=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_merge_df = merge_perm_results(rfc_perm_res_dfs)\n",
    "rfc_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40481892, 0.40483626, 0.39257452, 0.40856094, 0.41197281])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(rfc_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_lr_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_l1_lr_results.tsv\", sep=\"\\t\", index=False)\n",
    "l2_lr_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_l2_lr_results.tsv\", sep=\"\\t\", index=False)\n",
    "gbc_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_gbc_results.tsv\", sep=\"\\t\", index=False)\n",
    "rfc_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_rfc_results.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
