{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.metrics import f1_score\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt import gp_minimize\n",
    "\n",
    "import utils.dev_config as dev_conf\n",
    "import utils.preprocessing as prep\n",
    "import utils.optimization as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_conf.get_dev_directories(\"../dev_paths.txt\")\n",
    "unified_dsets = [\"unified_cervical_data\", \"unified_uterine_data\", \"unified_uterine_endometrial_data\"]\n",
    "matrisome_list = f\"{dirs.data_dir}/matrisome/matrisome_hs_masterlist.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrisome_df = prep.load_matrisome_df(matrisome_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rand = np.random.RandomState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and filter survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_code = {\"Alive\": 0, \"Dead\": 1}\n",
    "covariate_cols = [\"age_at_diagnosis\", \"race\", \"ethnicity\"]\n",
    "dep_cols = [\"figo_stage\"]\n",
    "cat_cols = [\"race\", \"ethnicity\"]\n",
    "survival_df = prep.load_survival_df(f\"{dirs.data_dir}/{unified_dsets[dset_idx]}/survival_data.tsv\", event_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 12)\n"
     ]
    }
   ],
   "source": [
    "filtered_survival_df = (\n",
    "    prep.decode_figo_stage(survival_df[[\"sample_name\"] + dep_cols + covariate_cols].dropna(), to=\"n\")\n",
    "        .pipe(pd.get_dummies, columns=cat_cols)\n",
    "        .reset_index(drop = True)\n",
    "        .pipe(prep.cols_to_front, [\"sample_name\", \"figo_num\"])\n",
    ")\n",
    "filtered_survival_df.columns = filtered_survival_df.columns.str.replace(' ', '_')\n",
    "print(filtered_survival_df.shape)\n",
    "# filtered_survival_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normalized matrisome count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1009)\n"
     ]
    }
   ],
   "source": [
    "norm_matrisome_counts_df = pd.read_csv(f\"{dirs.data_dir}/{unified_dsets[dset_idx]}/norm_matrisome_counts.tsv\", sep='\\t')\n",
    "norm_filtered_matrisome_counts_t_df = prep.transpose_df(\n",
    "    norm_matrisome_counts_df[[\"geneID\"] + list(filtered_survival_df.sample_name)], \"geneID\", \"sample_name\"\n",
    ")\n",
    "print(norm_filtered_matrisome_counts_t_df.shape)\n",
    "# norm_filtered_matrisome_counts_t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join survival and count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 1019)\n"
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    pd.merge(filtered_survival_df, norm_filtered_matrisome_counts_t_df, on=\"sample_name\")\n",
    "        .set_index(\"sample_name\")\n",
    ")\n",
    "print(joined_df.shape)\n",
    "# joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(seed)\n",
    "x_df, y_df = prep.shuffle_data(joined_df, rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent baseline: 0.3665158371040725\n",
      "Monte Carlo baseline: 0.3673247075043701\n"
     ]
    }
   ],
   "source": [
    "label_value_counts_df = (\n",
    "    pd.DataFrame(y_df.figo_num.value_counts()).reset_index()\n",
    "        .rename(columns={\"index\": \"label\", \"figo_num\": \"n\"})\n",
    "        .sort_values(\"n\", ascending=False)\n",
    ")\n",
    "\n",
    "most_frequent_label = label_value_counts_df.label[0]\n",
    "most_frequent_baseline = f1_score(y_df.values.squeeze(), np.repeat(most_frequent_label, y_df.shape[0]), average=\"weighted\")\n",
    "\n",
    "mc_baseline = opt.mc_classification_baseline(\n",
    "    y=y_df.values.squeeze(),\n",
    "    labels=label_value_counts_df.label.values,\n",
    "    weights=label_value_counts_df.n.values / label_value_counts_df.n.values.sum(),\n",
    "    metric=lambda y, yhat: f1_score(y, yhat, average=\"weighted\"),\n",
    "    n=1001\n",
    ")\n",
    "\n",
    "print(f\"Most frequent baseline: {most_frequent_baseline}\")\n",
    "print(f\"Monte Carlo baseline: {mc_baseline.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(h_params, X, y, scoring_default, r, verbose=True):\n",
    "    if verbose:\n",
    "        print(h_params)\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=h_params[0],\n",
    "        max_depth=h_params[1],\n",
    "        max_features=h_params[2],\n",
    "        min_samples_split=h_params[3],\n",
    "        min_samples_leaf=h_params[4],\n",
    "        bootstrap=h_params[5],\n",
    "        n_jobs=-1,\n",
    "        random_state=r\n",
    "    )\n",
    "    return -np.mean(cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=KFold(n_splits=5),\n",
    "        n_jobs=-1,\n",
    "        scoring=scoring_default\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [\n",
    "    Integer(int(1e2), int(1e3), name=\"n_estimators\"),\n",
    "    Integer(int(10), int(100), name=\"max_depth\"),\n",
    "    Categorical([\"auto\", \"sqrt\", \"log2\"], name=\"max_features\"),\n",
    "    Integer(int(2), int(4), name=\"min_samples_split\"),\n",
    "    Integer(int(1), int(3), name=\"min_samples_leaf\"),\n",
    "    Categorical([True, False], name=\"bootstrap\")\n",
    "]\n",
    "n_initial = 10 * len(space)\n",
    "n_calls = 50 * len(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_default = \"f1_weighted\"\n",
    "callback_file = f\"{unified_dsets[dset_idx]}_opt_rfc_h_params_{scoring_default}.tsv\"\n",
    "\n",
    "try:\n",
    "    os.remove(callback_file)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "res = gp_minimize(\n",
    "    lambda h_ps: objective(h_ps, x_df, y_df, scoring_default, rand),\n",
    "    space,\n",
    "    verbose=True,\n",
    "    random_state=rand,\n",
    "    n_initial_points=n_initial,\n",
    "    n_calls = n_calls,\n",
    "    n_jobs=-1,\n",
    "    callback=lambda x: opt.save_callback(x, callback_file, n = 5, sep=\"\\t\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
