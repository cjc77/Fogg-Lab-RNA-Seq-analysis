{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils.dev_config as dev_conf\n",
    "import utils.preprocessing as prep\n",
    "import utils.optimization as opt\n",
    "import utils.feature_selection as feat_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_conf.get_dev_directories(\"../dev_paths.txt\")\n",
    "unified_dsets = [\"unified_cervical_data\", \"unified_uterine_data\", \"unified_uterine_endometrial_data\"]\n",
    "matrisome_list = f\"{dirs.data_dir}/matrisome/matrisome_hs_masterlist.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrisome_df = prep.load_matrisome_df(matrisome_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "rand = np.random.RandomState()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and filter survival data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_code = {\"Alive\": 0, \"Dead\": 1}\n",
    "covariate_cols = [\"figo_stage\", \"age_at_diagnosis\", \"race\", \"ethnicity\"]\n",
    "dep_cols = [\"vital_status\", \"survival_time\"]\n",
    "cat_cols = [\"race\", \"ethnicity\", \"figo_chr\"]\n",
    "survival_df = prep.load_survival_df(f\"{dirs.data_dir}/{unified_dsets[dset_idx]}/survival_data.tsv\", event_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 16)\n"
     ]
    }
   ],
   "source": [
    "filtered_survival_df = (\n",
    "    prep.decode_figo_stage(survival_df[[\"sample_name\"] + dep_cols + covariate_cols].dropna(), to=\"c\")\n",
    "        .query(\"vital_status == 1\")\n",
    "        .drop([\"vital_status\"], axis=1)\n",
    "        .pipe(pd.get_dummies, columns=cat_cols)\n",
    "        .reset_index(drop = True)\n",
    ")\n",
    "filtered_survival_df.columns = filtered_survival_df.columns.str.replace(' ', '_')\n",
    "\n",
    "print(filtered_survival_df.shape)\n",
    "# filtered_survival_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load normalized matrisome count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 1009)\n"
     ]
    }
   ],
   "source": [
    "norm_matrisome_counts_df = pd.read_csv(f\"{dirs.data_dir}/{unified_dsets[dset_idx]}/norm_matrisome_counts.tsv\", sep='\\t')\n",
    "norm_filtered_matrisome_counts_t_df = prep.transpose_df(\n",
    "    norm_matrisome_counts_df[[\"geneID\"] + list(filtered_survival_df.sample_name)], \"geneID\", \"sample_name\"\n",
    ")\n",
    "print(norm_filtered_matrisome_counts_t_df.shape)\n",
    "# norm_filtered_matrisome_counts_t_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join survival and count data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 1023)\n"
     ]
    }
   ],
   "source": [
    "joined_df = (\n",
    "    pd.merge(filtered_survival_df, norm_filtered_matrisome_counts_t_df, on=\"sample_name\")\n",
    "        .set_index(\"sample_name\")\n",
    ")\n",
    "print(joined_df.shape)\n",
    "# joined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_gbr_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_gbr_h_params_explained_variance.tsv\", sep=\"\\t\")\n",
    "ev_gbrs = [\n",
    "    GradientBoostingRegressor(\n",
    "        **dict(zip(ev_gbr_h_param_df.columns[:-1], ev_gbr_h_param_df.iloc[i, :-1])), loss=\"ls\", random_state=rand\n",
    "    ) for i in range(ev_gbr_h_param_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_gbr_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_gbr_h_params_neg_mean_absolute_error.tsv\", sep=\"\\t\")\n",
    "mae_gbrs = [\n",
    "    GradientBoostingRegressor(\n",
    "        **dict(zip(mae_gbr_h_param_df.columns[:-1], mae_gbr_h_param_df.iloc[i, :-1])), loss=\"lad\", random_state=rand\n",
    "    ) for i in range(mae_gbr_h_param_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_rfr_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_rfr_h_params_explained_variance.tsv\", sep=\"\\t\")\n",
    "ev_rfrs = [\n",
    "    RandomForestRegressor(\n",
    "        **dict(zip(ev_rfr_h_param_df.columns[:-1], ev_rfr_h_param_df.iloc[i, :-1])), random_state=rand\n",
    "    ) for i in range(ev_rfr_h_param_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rfr_h_param_df = pd.read_csv(f\"{unified_dsets[dset_idx]}_opt_rfr_h_params_neg_mean_absolute_error.tsv\", sep=\"\\t\")\n",
    "mae_rfrs = [\n",
    "    RandomForestRegressor(\n",
    "        **dict(zip(mae_rfr_h_param_df.columns[:-1], mae_rfr_h_param_df.iloc[i, :-1])), random_state=rand\n",
    "    ) for i in range(mae_rfr_h_param_df.shape[0])\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect cross validated feature permutation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_feature_perm_results(models, x_df, y_df, r, gene_cols, score, verbose=True):\n",
    "    all_mean_perm_results = []\n",
    "    all_ref_scores = []\n",
    "    all_perm_res_dfs = []\n",
    "    \n",
    "    for i, m in enumerate(models):\n",
    "        if verbose:\n",
    "            print(f\"Running feature perm for model {i}\")\n",
    "        perm_results, ref_scores = opt.cv_permutation_importance(m, x_df, y_df, score, k=5, random_state=r)\n",
    "        perm_importances = np.concatenate([r.importances for r in perm_results], axis=1)\n",
    "        perm_importance_means = np.mean(perm_importances, axis=1)\n",
    "        \n",
    "        all_mean_perm_results.append(perm_importance_means)\n",
    "        all_ref_scores.append(ref_scores)\n",
    "        \n",
    "        res_df = feat_sel.gather_perm_res(x_df, perm_importance_means, np.mean(ref_scores), gene_cols)\n",
    "        res_df = res_df.rename(columns={\"mean_imp\": f\"mean_imp_{i}\", \"score_pct_improvement\": f\"score_pct_improvement_{i}\"})\n",
    "        all_perm_res_dfs.append(res_df)\n",
    "    \n",
    "    return all_mean_perm_results, all_ref_scores, all_perm_res_dfs\n",
    "\n",
    "\n",
    "def merge_perm_results(perm_res_dfs):\n",
    "    merge_df = perm_res_dfs[0]\n",
    "    for i in range(1, len(perm_res_dfs)):\n",
    "        merge_df = merge_df.merge(perm_res_dfs[i], on = \"geneID\", how = \"inner\")\n",
    "    merge_df = (\n",
    "        merge_df.assign(consensus_imp_mean = merge_df.filter(regex=\"mean_imp\").mean(axis=1))\n",
    "            .assign(consensus_imp_std = merge_df.filter(regex=\"mean_imp\").std(axis=1))\n",
    "    )\n",
    "    merge_df = merge_df.assign(consensus_imp_cv = merge_df.consensus_imp_std / merge_df.consensus_imp_mean)\n",
    "    merge_df[\"consensus_vote\"] = (merge_df.set_index(\"geneID\").filter(regex=\"mean_imp\", axis=1) > 0).all(axis=1).values\n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(seed)\n",
    "x_df, y_df = prep.shuffle_data(joined_df, rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 baseline: 641687.6988062444\n",
      "L1 baseline: 518.3333333333334\n",
      "R2 baseline: 0.0\n",
      "explained variance baseline: 0.0\n"
     ]
    }
   ],
   "source": [
    "mean_baseline = mean_squared_error(y_df.values, np.repeat(np.mean(y_df.values.squeeze()), y_df.shape[0]))\n",
    "median_baseline = mean_absolute_error(y_df.values, np.repeat(np.median(y_df.values.squeeze()), y_df.shape[0]))\n",
    "r2_baseline = r2_score(y_df.values, np.repeat(np.mean(y_df.values.squeeze()), y_df.shape[0]))\n",
    "expl_var_baseline = explained_variance_score(y_df.values, np.repeat(np.mean(y_df.values.squeeze()), y_df.shape[0]))\n",
    "\n",
    "print(f\"L2 baseline: {mean_baseline}\")\n",
    "print(f\"L1 baseline: {median_baseline}\")\n",
    "print(f\"R2 baseline: {r2_baseline}\")\n",
    "print(f\"explained variance baseline: {expl_var_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBR (Explained Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running feature perm for model 0\n"
     ]
    }
   ],
   "source": [
    "ev_gbr_mean_perm_res, ev_gbr_ref_scores, ev_gbr_perm_res_dfs = collect_feature_perm_results(\n",
    "    ev_gbrs, x_df, y_df, rand, norm_filtered_matrisome_counts_t_df.columns[1:], \"explained_variance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_gbr_merge_df = merge_perm_results(ev_gbr_perm_res_dfs)\n",
    "ev_gbr_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare metric with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ev_gbr_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBR (MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_gbr_mean_perm_res, mae_gbr_ref_scores, mae_gbr_perm_res_dfs = collect_feature_perm_results(\n",
    "    mae_gbrs, x_df, y_df, rand, norm_filtered_matrisome_counts_t_df.columns[1:], \"neg_mean_absolute_error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_gbr_merge_df = merge_perm_results(mae_gbr_perm_res_dfs)\n",
    "mae_gbr_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare metric with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mae_gbr_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFR (Explained variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_rfr_mean_perm_res, ev_rfr_ref_scores, ev_rfr_perm_res_dfs = collect_feature_perm_results(\n",
    "    ev_rfrs, x_df, y_df, rand, norm_filtered_matrisome_counts_t_df.columns[1:], \"explained_variance\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_rfr_merge_df = merge_perm_results(ev_rfr_perm_res_dfs)\n",
    "ev_rfr_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ev_rfr_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rfr_mean_perm_res, mae_rfr_ref_scores, mae_rfr_perm_res_dfs = collect_feature_perm_results(\n",
    "    mae_rfrs, x_df, y_df, rand, norm_filtered_matrisome_counts_t_df.columns[1:], \"neg_mean_absolute_error\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_rfr_merge_df = merge_perm_results(mae_rfr_perm_res_dfs)\n",
    "mae_rfr_merge_df.query(\"consensus_vote == True\").sort_values(\"consensus_imp_mean\", ascending=False).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(mae_rfr_ref_scores).mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_gbr_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_ev_gbr_results.tsv\", sep=\"\\t\", index=False)\n",
    "mae_gbr_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_mae_gbr_results.tsv\", sep=\"\\t\", index=False)\n",
    "ev_rfr_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_ev_rfr_results.tsv\", sep=\"\\t\", index=False)\n",
    "mae_rfr_merge_df.to_csv(f\"{dirs.analysis_dir}/{unified_dsets[dset_idx]}_mae_rfr_results.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
